{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "import time\n",
    "from unidecode import unidecode\n",
    "from itertools import chain\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/ik/Data/qa/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t_start = time.time()\n",
    "        res = func(*args, **kwargs)\n",
    "        print(\"f: {} # elapsed time: {:.0f} m {:.0f}s\".format(func.__name__.upper(), *divmod(time.time() - t_start, 60)))\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardsDataProcessor(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # dictionary that maps CATEGORIES to QUESTION NUMBERS;\n",
    "        # NOTE THE ABSENCE OF QUESTION 22!\n",
    "        self.CAT_QUES = {\"personal\": [_ for _ in range(1,8)] + [25] + [_ for _ in range(70,74)],\n",
    "                            \"children\": [_ for _ in range(11,22)] + [77,113,114],\n",
    "                            \"work\": [5] + [_ for _ in range(27,32)],\n",
    "                            \"finance\": [26] + [_ for _ in range(32,40)] + [115],\n",
    "                            \"insurance\": [40,66,67,81] + [_ for _ in range(84,90)],\n",
    "                            \"transportation\": [_ for _ in range(42,48)] + [91,92,116],\n",
    "                            \"phone\": [_ for _ in range(48,54)] + [59,60,80],\n",
    "                            \"internet\": [54,55,56,93],\n",
    "                            \"devices\": [57,58,62,117],\n",
    "                            \"health\": [63,64,65,118,119,120],\n",
    "                            \"shopping\": [61,68,69,94,95],\n",
    "                            \"property\": [8,9,10,41,90],\n",
    "                            \"media\": [75,76] + [_ for _ in range(109,113)],\n",
    "                            \"opt-ins\": [23,24,78,79,108],\n",
    "                            \"travel\": [_ for _ in range(96,103)],\n",
    "                            \"interests\": [74,82,83],\n",
    "                            \"drinks\": [_ for _ in range(103,108)]}\n",
    "\n",
    "        # reversed dictionary, question number -> category\n",
    "        self._QUES_CAT = {q:k for k, v in self.CAT_QUES.items() for q in v}  \n",
    "\n",
    "        # dictionary mapping QUESTION NUMBER to PROFILE ITEM\n",
    "        self.QUES_ITEM = {1: \"gender\", 2: \"dob\", 3: \"marital_status\", 4: \"home_postcode\",\n",
    "                        5: \"work_postcode\", 6: \"lives_in_state\", 7: \"lives_in_area\", 8: \"people_in_household\",\n",
    "                        9: \"housing_type\", 10: \"household_type\", 11: \"kids_u18_in_household\",\n",
    "                        12: \"childs_gender_dob\", 13: \"childs_gender_dob\", 14: \"childs_gender_dob\",\n",
    "                        15: \"childs_gender_dob\", 16: \"childs_gender_dob\", 17: \"childs_gender_dob\",\n",
    "                        18: \"childs_gender_dob\", 19: \"childs_gender_dob\", 20: \"childs_gender_dob\",\n",
    "                        21: \"childs_gender_dob\",\n",
    "                        22: \"\", \n",
    "                        23: \"wants_be_in_focus_group\", 24: \"wants_phone_interview\", \n",
    "                        25: \"education\", 26: \"main_salary_earner\", 27: \"employment_status\", \n",
    "                        28: \"industry\", 29: \"occupation\", 30: \"company_size\",\n",
    "                        31: \"company_annual_turnover\", 32: \"annual_income\", 33: \"annual_household_income\",\n",
    "                        34: \"ways_to_pay_bills\", 35: \"financial_services\", 36: \"financial_institutions\",\n",
    "                        37: \"main_financial_institutions\", 38: \"numb_credit_store_cards\",\n",
    "                        39: \"total_credit_limit\", 40: \"insurance_policies\", 41: \"home_ownership_status\",\n",
    "                        42: \"vehicle_owned\", 43: \"cond_most_used_vehicle_when_purchased\",\n",
    "                        44: \"vehicle_makes_owned\", 45: \"value_most_used_vehicle_when_purchased\",\n",
    "                        46: \"vehicle_types_owned\", 47: \"main_transport_to_work\", \n",
    "                        48: \"owns_mobile\", 49: \"mobile_brand\", 50: \"who_pays_mobile\",\n",
    "                        51: \"mobile_network\", 52: \"mobile_on_contract\", 53: \"mobile_contract_expiration\",\n",
    "                        54: \"internet_at_home\", 55: \"type_internet_at_home\", 56: \"isp\",\n",
    "                        57: \"owns_computer\", 58: \"computer_type\", 59: \"landline_at_home\", \n",
    "                        60: \"landline_provider\", 61: \"online_purchasing_freq\",\n",
    "                        62: \"owns_devices\", 63: \"smoker\", 64: \"wears_glasses_or_lenses\",\n",
    "                        65: \"conditions_suffered\", 66: \"has_health_insurance\", \n",
    "                        67: \"private_health_insurance_with\", 68: \"role_in_buying_groceries\",\n",
    "                        69: \"buying_groceries_online\", 70: \"born_in\", 71: \"ancestry\",\n",
    "                        72: \"languages_at_home\", 73: \"religion\", 74: \"pets\", 75: \"pay_tv_at_home\",\n",
    "                        76: \"pay_tv_provider\", 77: \"total_kids\", 78: \"okayed_kids_online_surveys\",\n",
    "                        79: \"wants_sms_offers\", 80: \"mobile_number\", 81: \"vehicle_insurance_expiration\",\n",
    "                        82: \"owns_swimming_pool\", 83: \"interested_in_activities\", \n",
    "                        84: \"home_building_insurance_expiration\",\n",
    "                        85: \"home_contents_insurance_expiration\", 86: \"life_insurance_expiration\",\n",
    "                        87: \"health_insurance_expiration\", 88: \"boat_insurance_expiration\",\n",
    "                        89: \"caravan_insurance_expiration\", 90: \"bought_home_in\",\n",
    "                        91: \"total_vehicles_in_household\", 92: \"year_bought_most_used_vehicle\",\n",
    "                        93: \"social_networks\", 94: \"main_supermarkets_for_groceries\", \n",
    "                        95: \"regularly_shops_at_department_stopes\", 96: \"member_of_frequent_flyer\",\n",
    "                        97: \"flights_past_12_months\", 98: \"purpose_flying_past_12_months\",\n",
    "                        99: \"how_often_would_fly_for_business_a_year\", \n",
    "                        100: \"how_often_would_fly_for_leisure_a_year\",\n",
    "                        101: \"on_holidays_goes_to\", 102: \"rented_a_car_past_12_months\",\n",
    "                        103: \"regular_alcoholic_drinks\", 104: \"energy_drinks\",\n",
    "                        105: \"sports_drinks\", 106: \"bottles_wine_a_month_at_household\",\n",
    "                        107: \"how_much_ok_to_spend_bottle_wine\", 108: \"wants_wine_offers\",\n",
    "                        109: \"reads_newspapers\", 110: \"reads_magazines\", 111: \"watches_sports\",\n",
    "                        112: \"reads_news_portals\", 113: \"is_pregnant\", 114: \"baby_due\",\n",
    "                        115: \"credit_card_types\", 116: \"plans_to_purchase_vehicle\", \n",
    "                        117: \"deviced_purchased_upgraded_past_12_month\", 118: \"type_of_cigarettes\",\n",
    "                        119: \"brands_of_cigarettes\", 120: \"brands_of_cigarette_papers\"}\n",
    "        \n",
    "    def get_month_year(self, st):\n",
    "        \"\"\"\n",
    "        IN: a string expected to be a datetime like \"Aug 14 2013  6:08PM\"\n",
    "        OUT: a string that only contains months and year extracted from the input string; format is '03/2016'\n",
    "        \"\"\"\n",
    "    \n",
    "        # empty st - return None straight away\n",
    "        if not st:\n",
    "            return None\n",
    "    \n",
    "        # is there are quotes, remove; create list of words in string\n",
    "        wrd_lst = str(st).replace(\"'\",\"\").replace('\"',\"\").split()\n",
    "    \n",
    "        # if st clearly doesn't look like \"Aug 14 2013  6:08PM\", return none\n",
    "        if len(wrd_lst) != 4:\n",
    "            return None\n",
    "        else:\n",
    "            try:\n",
    "                \"\"\"\n",
    "                %b - Month as localeâ€™s abbreviated name.\n",
    "                %d - Day of the month as a zero-padded decimal number.\n",
    "                %Y - Year with century as a decimal number.\n",
    "                \"\"\"\n",
    "                extracted_date = datetime.strptime(\" \".join(wrd_lst[:-1]), \"%b %d %Y\").strftime(\"%m/%Y\") \n",
    "            except:\n",
    "                # most likely in case the format happens to be wrong - then just return None\n",
    "                extracted_date = None\n",
    "    \n",
    "        return extracted_date\n",
    "\n",
    "    @timer\n",
    "    def read_original_responses(self):\n",
    "    \n",
    "        # read responses, interpret everything as strings; NOTE: member pks will be strings too\n",
    "        self._resp = pd.read_csv(DATA_DIR + \"profileresponses.txt\", sep=\"|\", encoding='latin-1', dtype=str)\n",
    "        self._resp[\"RespondedTime\"] = self._resp[\"RespondedTime\"].str.lower().apply(self.get_month_year)\n",
    "        self._resp[\"ResponseDate\"] = self._resp[\"ResponseDate\"].apply(self.get_month_year)\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    @timer\n",
    "    def read_original_questions_answers_customers(self):\n",
    "        \n",
    "        self._questions = pd.read_csv(DATA_DIR + \"Questions.txt\", sep=\"|\", dtype=str)\n",
    "        \n",
    "        self._answers = pd.read_csv(DATA_DIR + \"Answers.txt\", sep=\"|\", dtype=str)\n",
    "        self._answers[\"Descr\"] = self._answers[\"Descr\"].apply(lambda _: _.split(\";\")[-1].strip().lower())\n",
    "        \n",
    "        self._customers = pd.read_csv(DATA_DIR + \"YC_member.txt\", sep=\"|\", encoding='latin-1', dtype=str)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    @timer\n",
    "    def create_cust_name_id_dict(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        create a dictionary of the sort {\"member_pk\": {\"name\": john, \"last_name\": \"snow\", \"cust_id\": 9465722},...}\n",
    "        \"\"\"\n",
    "        self._names_by_mpk_dict = (self._customers.loc[:, [\"member_pk\", \"FirstName\", \"LastName\", \"TicketekCustomerID\"]].set_index(\"member_pk\")\n",
    "                                  .rename(columns={\"FirstName\": \"name\", \"LastName\": \"last_name\", \"TicketekCustomerID\": \"cust_id\"})\n",
    "                                  .applymap(lambda _: unidecode(str(_).lower().strip()))\n",
    "                                  .to_dict(orient='index'))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    @timer\n",
    "    def merge_responses_and_names(self):\n",
    "        \n",
    "        self._rn = (self._resp.merge(self._answers.loc[:,[\"Answer_PK\", \"Question_PK\", \"Descr\"]], \n",
    "                left_on=['Answer_PK',\"Question_PK\"], right_on=['Answer_PK',\"Question_PK\"], how='inner'))\n",
    "#                  .merge(self._customers.loc[:,[\"member_pk\",\"FirstName\", \"LastName\", \"TicketekCustomerID\"]], \n",
    "#                         left_on=\"Member_PK\", right_on=\"member_pk\", how=\"inner\"))\n",
    "\n",
    "        self._rn[\"Item\"] = self._rn[\"Question_PK\"].apply(lambda x: self.QUES_ITEM[int(x)] if int(x) in self.QUES_ITEM else x)\n",
    "        self._rn[\"Category\"] = self._rn[\"Question_PK\"].apply(lambda x: self._QUES_CAT[int(x)] if int(x) in self._QUES_CAT else x)\n",
    "        \n",
    "        self._rn.loc[:,\"FullResponse\"] = ((self._rn.loc[:,\"ResponseText\"].fillna('') + '&' + self._rn.loc[:,\"ResponseDate\"].fillna(''))\n",
    "                                            .apply(lambda x: tuple(w if w else None for w in x.split(\"&\"))))\n",
    "        \n",
    "        # where FullResponse is a tuple of two None, the real reply is in Descr\n",
    "        bool_where_nones = self._rn.loc[:,\"FullResponse\"].apply(lambda _: all(w is None for w in _))\n",
    "        self._rn.loc[bool_where_nones, \"Reply\"] = self._rn.loc[bool_where_nones,\"Descr\"]\n",
    "        self._rn.loc[~bool_where_nones, \"Reply\"] = self._rn.loc[~bool_where_nones,\"FullResponse\"]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    @timer\n",
    "    def split_df(self, df, PREF_CHUNK_SIZE=200000):\n",
    "        \n",
    "        \"\"\"\n",
    "        helper function that splits data frame df into chunks based on the\n",
    "        preferred chunk size(in rows) PREF_CHUNK_SIZE\n",
    "        \"\"\"\n",
    "        # how many unique member oks in df?\n",
    "        #print(df.columns)\n",
    "        n = len(df.Member_PK.unique())\n",
    "        # so how many chunks will be needed? \n",
    "        chunks = n//PREF_CHUNK_SIZE + (n%PREF_CHUNK_SIZE > 0)\n",
    "        # sorted list of all member pks\n",
    "        srt_pks = sorted(list(set(df.Member_PK)))\n",
    "        print(\"splitting data frame into {} chunks...\".format(chunks))\n",
    "        \n",
    "        return [df.loc[df.Member_PK.isin(srt_pks[i*PREF_CHUNK_SIZE: (i+1)*PREF_CHUNK_SIZE]), :] \n",
    "                                                                                for i in range(chunks)]\n",
    "    def series_to_tuple(self, ser):\n",
    "        \"\"\"\n",
    "        IN: ser - a pandas series\n",
    "        OUT: a tuple containing all elements of ser\n",
    "        \"\"\"\n",
    "        return tuple([v if v else v for v in ser])\n",
    "    \n",
    "    def list_tuples_to_list_dicts(self, lst_tuples):\n",
    "        return [{lst_tuples[0][i]: lst_tuples[1][i]} for i in range(len(lst_tuples[0]))]\n",
    "    \n",
    "    @timer\n",
    "    def collect_responses(self, df, ll=['Member_PK', \"Category\", \"Item\"], al=[\"Reply\", \"RespondedTime\"]):\n",
    "    \n",
    "        grouped_by_member_pk = df.groupby('Member_PK')  # Member_PK becomes index\n",
    "        dict_list = []\n",
    "    \n",
    "        i = 0\n",
    "        \n",
    "        for mpk, d in grouped_by_member_pk:\n",
    "        \n",
    "            cust_dict = dict()   \n",
    "            cust_data = d[[\"Category\", \"Item\", \"Reply\", \"RespondedTime\"]].groupby([\"Category\", \"Item\"]).agg(self.series_to_tuple)\n",
    "            \"\"\"\n",
    "            cust_data has Category and Item as indices:\n",
    "                                                               Reply RespondedTime\n",
    "                                            Category Item                         \n",
    "                                            personal gender  (male,)    (10/2007,)\n",
    "            \"\"\"\n",
    "            for row in cust_data.iterrows():\n",
    "                \n",
    "                \"\"\"\n",
    "                row[0] is a tuple of (category_name, item_name)\n",
    "                row[1] is a series with named entries\n",
    "                \n",
    "                -- case 1:\n",
    "                \n",
    "                row[1][Reply] is a tuple like \n",
    "                            (coles, aldi, woolworths, iga / supa iga)\n",
    "                while row[1][\"RespondedTime\"] is another tuple with matching times:\n",
    "                             (12/2011, 12/2011, 12/2011)\n",
    "                             \n",
    "                -- case 2:\n",
    "                \n",
    "                row[1][Reply] can be like\n",
    "                            ((None, 01/2003),)\n",
    "                and row[1][\"RespondedTime\"] is still (12/2011,)\n",
    "                \n",
    "                -- case 3 (children details):\n",
    "                \n",
    "                row[1][Reply] is ((female, 01/2005), (female, 01/2007))\n",
    "                and row[1][\"RespondedTime\"] is (10/2007, 10/2007)\n",
    "                \n",
    "                \"\"\"\n",
    "                category_name, item_name = row[0]\n",
    "                \n",
    "                \n",
    "                if isinstance(row[1][\"Reply\"][0], tuple):\n",
    "                    if all(row[1][\"Reply\"][0]):\n",
    "                        r = {tp[0]: tp[1] for tp in row[1][\"Reply\"]}\n",
    "                    else:\n",
    "                        r = {[tuple_part for tuple_part in row[1][\"Reply\"][0] if tuple_part][0]: row[1][\"RespondedTime\"][0]}\n",
    "                else:\n",
    "                    r = {row[1][\"Reply\"][i]: row[1][\"RespondedTime\"][i] for i in range(len(row[1][\"Reply\"]))}\n",
    "                \n",
    "                if mpk in cust_dict:\n",
    "                    \n",
    "                    if category_name in cust_dict[mpk]:\n",
    "                        cust_dict[mpk][category_name].update({item_name: r})\n",
    "                    else:\n",
    "                        cust_dict[mpk].update({category_name: {item_name: r}})\n",
    "                else:\n",
    "                    cust_dict.update({mpk: {category_name: {item_name: r}}})\n",
    "                \n",
    "                if mpk in self._names_by_mpk_dict:\n",
    "                    cust_dict[mpk].update(self._names_by_mpk_dict[mpk])\n",
    "                    \n",
    "                \n",
    "        \n",
    "            dict_list.append(cust_dict)\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            if i % 5000 == 0:\n",
    "                print(\"processed {} customers\".format(i))\n",
    "        \n",
    "        # now every dictionary in dict_list is like {rewards_id: {everything else}} but we'd like\n",
    "        # to flatten this a little so that rewards_id would become just another key in the everything else\n",
    "        # part\n",
    "        \n",
    "        new_dict_list = []\n",
    "        \n",
    "        for d in dict_list:\n",
    "            for k in d:\n",
    "                temp_dict = {\"rewards_id\": k}\n",
    "                temp_dict.update(d[k])\n",
    "                new_dict_list.append(temp_dict)\n",
    "        \n",
    "        return new_dict_list\n",
    "    \n",
    "    @timer\n",
    "    def collect_responses_parallel(self):\n",
    "        \n",
    "        self.rsps = []\n",
    "        \n",
    "        df_split = self.split_df(self._rn, PREF_CHUNK_SIZE=10000)  # [df1, df2, ..]\n",
    "        \n",
    "        npairs = len(df_split)//2\n",
    "        \n",
    "        for i in range(npairs):\n",
    "            pool = Pool(2)  \n",
    "            print(\"made pool\")\n",
    "            lst_dicts = pool.map(self.collect_responses, df_split[i*2:(i+1)*2])\n",
    "            print(\"did map\")\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            \n",
    "            print(\"extending list\")\n",
    "            self.rsps.extend([d for l in lst_dicts for d in l])\n",
    "            print(\"dicts collected so far: {}\".format(len(self.rsps)))\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    rp = (RewardsDataProcessor()\n",
    "            .read_original_responses()\n",
    "            .read_original_questions_answers_customers()\n",
    "            .create_cust_name_id_dict()\n",
    "            .merge_responses_and_names())\n",
    "    \n",
    "    rsp = rp.collect_responses(rp._rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(rsp, open('rewards-qa-data-18102017.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
